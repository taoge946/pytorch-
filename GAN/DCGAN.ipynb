{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,) , (0.5,))#均值和方差设为0.5就是将取值范围从0~1放到了-1~1\n",
    "    ###注！！！！！Normalize不能直接(0.5,0.5) 要改成上面那样，推测是torch版本导致的\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=torchvision.datasets.MNIST('data',train=True,transform=transform,download=True)\n",
    "dataloader=torch.utils.data.DataLoader(train_ds,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z=torch.randn(batchsize,100,1,1) #可以这么定义噪声，这样就是一个channel为100的1*1的噪声，就不用再s使用linear层和reshape了（在pytorch中第一个维度是c）\n",
    "batchsize=64\n",
    "z=torch.randn(batchsize,100)#这里为了更直观一点就加linear层了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear1=nn.Linear(100,256*7*7) #为什么选7*&因为两次反卷积之后就是minist的28*28了\n",
    "        self.bn1=nn.BatchNorm1d(256*7*7) #因为此时是一维的所以用1d\n",
    "        self.deconv1=nn.ConvTranspose2d(256,128, #我们要使通道数越来越小直到1（灰度图像）\n",
    "                                kernel_size=(3,3),#卷积核一般都是3*3，也可以定义成其他的\n",
    "                                stride=1,#7->28只需要反卷积两次，但是为了提高反卷积层的生成能力，可以把跨度设为1，不进行缩放，可以多加几层反卷积\n",
    "                                padding=1)#要是不进行缩放的话卷积核为3就得进行1的填充\n",
    "                                    #(128,7,7)\n",
    "        self.bn2=nn.BatchNorm2d(128)\n",
    "        self.deconv2=nn.ConvTranspose2d(128,64,kernel_size=(4,4),stride=2,padding=1) #为了使生成图片大小正好是14*14的，所以调整了一下卷积核\n",
    "                                    #(64，14,14)\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.deconv3=nn.ConvTranspose2d(64,1,kernel_size=(4,4),stride=2,padding=1) \n",
    "                                    #(1,28,28)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.linear1(x))\n",
    "        x=self.bn1(x)\n",
    "        x=x.view(-1,256,7,7)\n",
    "        x=F.relu(self.deconv1(x))\n",
    "        x=self.bn2(x)\n",
    "        x=F.relu(self.deconv2(x))\n",
    "        x=self.bn3(x)\n",
    "        x=torch.tanh(self.deconv3(x))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear1): Linear(in_features=100, out_features=12544, bias=True)\n",
       "  (bn1): BatchNorm1d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,64,3,stride=2) #判别器的输入不能有BN层\n",
    "        self.conv2=nn.Conv2d(64,128,3,stride=2)\n",
    "        self.bn=nn.BatchNorm2d(128)\n",
    "        self.Fc=nn.Linear(128*6*6,1)\n",
    "    def forward(self,x):\n",
    "        x=F.dropout2d(F.leaky_relu(self.conv1(x)))#注意在判别器中使用leakyrelu进行激活  使用dropout层来使得判别器不会过强\n",
    "        x=F.dropout2d(F.leaky_relu(self.conv2(x)))#现在的输出结果为(batch,128,6,6)\n",
    "        x=self.bn(x)\n",
    "        x=x.view(-1,128*6*6) #除了batch外将图片的数据展平\n",
    "        x=torch.sigmoid(self.Fc(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay=nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=torch.randn(8,128,7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=lay(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 12, 12])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gen=Generator().to(device)\n",
    "dis=Discriminator().to(device)\n",
    "loss_fn=nn.BCELoss()\n",
    "g_optim=torch.optim.Adam(gen.parameters(),lr=1e-4) #可以使生成器的学习速率大于判别器从而避免判别器过强\n",
    "d_optim=torch.optim.Adam(dis.parameters(),lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_save_img(model,epoch,test_input):\n",
    "    pre=np.squeeze(model(test_input).cpu().numpy())\n",
    "    fig=plt.figure(figsize=(4,4))\n",
    "    for i in range(pre.shape[0]): #这里得用中括号\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow((pre[i]+1)/2,cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input=torch.randn(16,100,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss=[]\n",
    "G_loss=[]#建立两个空列表来存损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(40):\n",
    "    d_epoch_loss=0\n",
    "    g_epoch_loss=0\n",
    "    count=len(dataloader) #a=len(dataloader)会返回batch数，b=len(dataset)会返回样本总数 （b=a*batch_size）\n",
    "\n",
    "    for step, (img, _) in enumerate(dataloader):#需要epoch号和图像，不需要标签\n",
    "        img=img.to(device)#先把数据放到GPU上\n",
    "        size=img.size(0)#相当于batch_size，生成这么多个随机数正好和一个批次的图像向对应\n",
    "        random_noise=torch.randn(size,100,device=device)\n",
    "        \n",
    "        #判别器的损失\n",
    "        d_optim.zero_grad() #对于判别器而言损失有两个部分,真实图像的损失和生成图像的损失\n",
    "        real_output=dis(img) #判别器输入真实的图片，得到对真实图片的预测结果，我们希望real_output为1\n",
    "        d_real_loss=loss_fn(real_output,#因为我们对真实图片希望输出结果是1，所以计算它和全1的数组\n",
    "                    torch.ones_like(real_output)) #torch.ones_like(a)是输出a的样式那么多个1，如a是5*5的数组，这个就输出5*5的1\n",
    "        d_real_loss.backward()\n",
    "\n",
    "        gen_img=gen(random_noise)\n",
    "        fake_output=dis(gen_img.detach())#判别器输入生成的图片，因为这里也是对判别器的训练，所以使用detach将梯度截取不影响gen的训练，使梯度不再传送到gen的模型中了\n",
    "        d_fake_loss=loss_fn(fake_output,torch.zeros_like(fake_output))\n",
    "        d_fake_loss.backward()\n",
    "\n",
    "        d_loss=d_real_loss+d_fake_loss\n",
    "        d_optim.step()\n",
    "\n",
    "        #生成器的损失\n",
    "        g_optim.zero_grad()\n",
    "        fake_output=dis(gen_img) #此时就不需要截断了，因为此时就需要梯度来训练优化GAN\n",
    "        g_loss=loss_fn(fake_output,torch.ones_like(fake_output)) #对于生成器我们希望判别器判断的的结果为1,就是希望生成的图片被判断为真\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        with torch.no_grad():#将每个epoch中批次的的所有loss求和\n",
    "            d_epoch_loss+=d_loss.item() #得到的loss是标量tensor，使用item获取它的值\n",
    "            g_epoch_loss+=g_loss.item()\n",
    "    with torch.no_grad():  #求每个epoch的平均loss再放到列表中\n",
    "        d_epoch_loss/=count\n",
    "        g_epoch_loss/=count\n",
    "        D_loss.append(d_epoch_loss)\n",
    "        G_loss.append(g_epoch_loss)\n",
    "        print('Epoch:',epoch)\n",
    "        gen_and_save_img(gen,epoch,test_input)#使用一个固定的噪声而不是每个epoch都变的噪声从而更明显的看出来优化变化的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e0cf7bb98562de34716794ec83dc094d5ce5d166fa826bddfbc7345b697c299"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('text')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
